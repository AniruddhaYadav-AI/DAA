Despite having a simple architecture, selection sort is a comparison-based algorithm whose correctness can be formally shown through the use of algorithmic termination and loop invariants. We explain the logic behind this proof below.

1. Invariant Loop
A condition that is true both before and after a loop iteration is known as a loop invariant. The loop invariant for selection sort makes sure that following the i-th iteration of the outer loop:

Arr[0:i], the subarray, is completely sorted.
Every element in the remaining unsorted subarray arr[i:n], where n is the array's total length, is less than or equal to every element in this sorted subarray.
Determining the Invariant: Since the subarray arr[0:0] is empty at the beginning, before the first iteration (i = 0), it can be sorted easily. Consequently, the initial loop invariant holds.

Preserving the Invariant: Every time iteration, selection sort locates the smallest element in the array's unsorted section and replaces it with the section's initial element. By doing this step, the subarray arr[0:i+1] stays sorted and the element at index i is the smallest in the array by the end of the i-th iteration. As a result, the loop invariant is maintained during the loop's execution.
Termination and the Invariant: The loop invariant ensures that arr[0:n-1] is sorted after the loop ends (after n-1 iterations). 
Given that the final piece slips into position by itself, this suggests that the array as a whole has been sorted. As a result, the process ends with a sorted array.

2. Verification of Accuracy
The following evidence supports the selection sort's correctness:

Initialization: The subarray arr[0:0] is easily sorted prior to the first iteration.
Maintenance: The loop invariant makes sure that all of the items in the sorted subarray are fewer than or equal to those in the unsorted section, and that the sorted subarray expands by one element with each iteration.
Termination: The array is entirely sorted after n-1 repetitions. The invariant makes sure that every element is in its proper place and that there are no more unsorted items.

3. An Illustration of Correctness
Take, for instance, the array [64, 25, 12, 22, 11]:

i=0 in the first iteration:
Eleven is the smallest element of arr[0:5]. The outcomes of swapping 11 for 64 are [11, 25, 12, 22, 64]. Now that the subarray [11] is sorted.

Iteration two (i=1):
There are twelve elements in arr[1:5]. If you swap out 12 with 25, you get [11, 12, 25, 22, 64]. [11, 12] are now sorted.

Iteration three (i=2):
22 is the smallest element found in arr[2:5]. The outcomes of swapping 22 for 25 are [11, 12, 22, 25, 64]. We have sorted the subarray [11, 12, 22].

Iteration four (i=3):
25 is the smallest element in arr[3:5], and it is already positioned correctly. [11, 12, 22, 25] is sorted as a result.

Last iteration (where i=4):
The process stops here since the array has been entirely sorted. [11, 12, 22, 25, 64] is the final array.

4. Taking Time Complexity Into Account
Although selection sort is simple to comprehend and use, it is not very effective. Selection sort always has an O(n^2) time complexity, where n is the number of entries in the array. This inefficiency results from:

The approach uses two nested loops: to identify the minimal element, the inner loop iterates n times for each pass, while the outer loop iterates n times. There are a quadratic number of comparisons as a result.
The number of comparisons is independent of the starting element arrangement, hence the worst-case and average-case time complexities are equally O(n^2). Selection sort does not profit from a "best-case" situation where fewer comparisons could be required, in contrast to other algorithms like insertion sort.
