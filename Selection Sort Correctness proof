Arguing Selection Sort Correctness 
Selection sort is a simple, comparison-based sorting algorithm. Its correctness can be formally proven through the concepts of loop invariants and termination. 

1. Loop Invariant
A loop invariant is a condition that is true before and after every iteration of a loop. In the case of selection sort, the invariant guarantees that after the i-th iteration of the outer loop:

The subarray arr[0:i] is sorted.
Every element in the sorted subarray is less than or equal to every element in the unsorted subarray arr[i:n], where n is the length of the array.
Establishing the Invariant
Initially, at the start of the first iteration (i = 0), the subarray arr[0:0] is considered trivially sorted (an empty subarray). Hence, the loop invariant holds true.

Maintaining the Invariant
At the beginning of each iteration, selection sort identifies the smallest element in the unsorted portion of the array and swaps it with the first element of that portion. This ensures that after the i-th iteration, the element at index i is the smallest element in the remaining array. Therefore, arr[0:i+1] is sorted, and the invariant holds after every loop iteration.

Termination of the Invariant
When the loop finishes (after n-1 iterations), the invariant tells us that arr[0:n-1] is sorted, meaning the entire array is sorted because the last element is automatically in the correct position. Thus, the algorithm terminates with a sorted array.

2. Proof of Correctness
We can now argue that the algorithm is correct based on these two points:

Initialization: Before the first iteration, the subarray arr[0:0] is trivially sorted.
Maintenance: By the loop invariant, after each iteration, the sorted subarray grows by one element, and the elements in the sorted subarray are less than or equal to those in the unsorted subarray.
Termination: After n-1 iterations, the entire array is sorted because there are no remaining unsorted elements, and the invariant guarantees that all elements are in their correct positions.
3. Correctness Example
Consider the array: [64, 25, 12, 22, 11].

First iteration (i=0):

The smallest element in arr[0:5] is 11. Swap 11 with 64, resulting in the array: [11, 25, 12, 22, 64]. The subarray [11] is sorted.
Second iteration (i=1):

The smallest element in arr[1:5] is 12. Swap 12 with 25, resulting in: [11, 12, 25, 22, 64]. Now, the subarray [11, 12] is sorted.
Third iteration (i=2):

The smallest element in arr[2:5] is 22. Swap 22 with 25, resulting in: [11, 12, 22, 25, 64]. The subarray [11, 12, 22] is sorted.
Fourth iteration (i=3):

The smallest element in arr[3:5] is 25, which is already in place. The subarray [11, 12, 22, 25] is sorted.
Final iteration (i=4):

The array is already sorted, so the algorithm terminates.
Final array: [11, 12, 22, 25, 64].

4. Time Complexity Consideration
While selection sort is correct and simple, it is not very efficient. The time complexity of selection sort is always O(n^2), where n is the number of elements in the array. This is because:

There are two nested loops: the outer loop runs n times, and for each iteration of the outer loop, the inner loop runs n-i times to find the minimum element, leading to a quadratic number of comparisons.
The worst-case and average-case time complexities are the same (O(n^2)) because the algorithm always performs the same number of comparisons, regardless of the initial arrangement of elements. There are no "best-case" improvements like those seen in some other sorting algorithms (e.g., insertion sort with nearly sorted data).

Conclusion
Selection sort is correct because the loop invariant guarantees that the subarray before the current index is sorted, and the smallest element is always placed in its correct position.
The algorithm terminates with the entire array sorted, having gone through each element once.
The time complexity is O(n^2), making it inefficient for large datasets, but it is simple to implement and analyze.
